# Neural Networks

* Neural networks are an alternative to feature crosses. Provide more flexibility in modeling higher order, complex relationships in the dataset
* They comprise of hidden layers alongside activation functions
* Activation functions add the non-linearity to the model
	* Popular ones are sigmoid function, and ReLU (max(0, wx+b))
		* ReLU is very powerful 
	* different layers can have diff activation functions
* value of any node in a network is the `activation_function(wx+b)`
* edges are the weights 

## Additional Reading

* https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/

## Resources
* Course Links:
	* Neural Networks: Structure https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/anatomy
