# Regularization: Sparsity
|
## L1 Regularization
* L<sub>1</sub> Regularization drives model weights to exactly zero. Uses `sum(|weights|)`
* L<sub>2</sub> Regularization drives model weights *close* to zero but not entirely zero
* L<sub>1</sub> Regularization is useful when you have a lot of features (a wide model) and want to zero out the ones that aren't useful to save up on on memory. 
* L<sub>0</sub> Regularization

## Resources

* Course Links:
	* L1 Regularization: https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization